{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed089f8-7d61-4550-9686-02f50a53a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libarary\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import glob, os\n",
    "import random\n",
    "def converted():\n",
    "    paths = r'C:\\Users\\admin\\Documents\\test\\converted'\n",
    "    my_list = os.listdir(paths)\n",
    "    output = r'C:\\Users\\admin\\Documents\\test\\converted_new'\n",
    "    combine = 'converted_combine_txt.txt'\n",
    "    a = ['Trang','Nhi','Nhung','Dung','Vy','Khang','Khanh','Khoa','Vinh','Hoa','Anh','Kim','Nga','Nghi',\n",
    "        'Lan','Phong','Long','Sang','Chi','Huynh','Loan','Di','Duy','Minh','Thy','Thu','Thi','Ly','My',\n",
    "        'Nam','Thanh','Mai','An','Kha','Linh','Bi','Tuy','Em','Huy','Trung','Chung','Sa','Giang','Gia',\n",
    "        'Na','Nhu','Quang','Quy','Phi','Ti','Trinh','Nho','Nhu']\n",
    "\n",
    "\n",
    "    def convert_to_multiple_files(path_to_convert_file):\n",
    "        in_csv = r'{}'.format(path_to_convert_file)\n",
    "        #get the number of lines of the csv file to be read\n",
    "        number_lines = sum(1 for row in (open(in_csv)))\n",
    "        rowsize = 200\n",
    "        header= ['First Name','Last Name','Phone']\n",
    "        #start looping through data writing it to a new file for each set\n",
    "        for i in range(0,number_lines,rowsize):\n",
    "            df_split = pd.read_csv(in_csv, dtype = 'str',\n",
    "                nrows = rowsize,#number of rows to read at each loop\n",
    "                skiprows = i)#skip rows that have been read\n",
    "            df_split.columns = header\n",
    "            #csv to write data to a new file with indexed name. input_1.csv etc.\n",
    "            out_csv = f'{output}\\\\{list_1}\\\\convert_multiple_' + str(i) + '.csv'\n",
    "            # d = f'{output}\\\\{list_1}'\n",
    "            df_split.to_csv(out_csv,\n",
    "                index=False,\n",
    "                header=True,\n",
    "                mode='a',#append data to csv file\n",
    "                chunksize=rowsize)#size of data to append for each loop\n",
    "\n",
    "    def split_files(path_comb):\n",
    "        # split uid|phone to 2 column UID, Phone\n",
    "        df = pd.read_csv(r'{}'.format(path_combine))\n",
    "        df[['Phone','UID']] = df['Uid|Phone'].str.split(\"|\",expand=True)\n",
    "        df_1 = df['Phone']\n",
    "        df_1_csv =  df_1.to_csv(r'{}'.format(path_combine), index = None)\n",
    "        \n",
    "        # create columns 'First Name', 'Last name', 'Phone'.\n",
    "        df_1_csv = pd.read_csv(r'{}'.format(path_combine),dtype = 'str')\n",
    "        df_1_csv[['First Name', 'Last name']] = ''\n",
    "        df_2_csv = df_1_csv.reindex(columns=['First Name','Last Name','Phone'])    \n",
    "        \n",
    "        keep= [\"086\",\"096\",\"097\",\"098\",\"032\",\"033\",\n",
    "            \"034\",\"035\",\"036\",\"037\",\"038\",\"039\",# Vietel\n",
    "            \"089\",\"090\",\"093\",\"070\",\"079\",\"077\",\"076\",\"078\" # Mobifone\n",
    "            ,\"088\",\"091\",\"094\",\"083\",\"084\",\"085\",\"081\",\"082\", # Vinaphone\n",
    "            \"092\",\"056\",\"058\"] # Vietnamobile\n",
    "        \n",
    "        #filter for rows that contain the partial string \"Wes\" in the conference column\n",
    "        df_2_csv = df_2_csv[df_2_csv.Phone.str.contains('|'.join(keep))]\n",
    "        df_dup = df_2_csv.drop_duplicates(keep='first')\n",
    "        # df_dup.to_csv(r'{}'.format(path_combine), index = None)\n",
    "        # print(df_dup)\n",
    "        _list = []\n",
    "        for i in range(0, len(df_dup)):\n",
    "            item = random.choices(a)\n",
    "            item = str(item[0])\n",
    "            _list.append(item)\n",
    "        df_dup['Last Name'] = _list    \n",
    "        print(df_dup)\n",
    "        df_dup.to_csv(r'{}'.format(path_combine), index = None)\n",
    "\n",
    "    for list_1 in my_list:\n",
    "        os.mkdir(f'{output}\\\\{list_1}')\n",
    "        d = f'{output}\\\\{list_1}'\n",
    "        # print(list_1)\n",
    "        my_list_1 = os.listdir(r'{}\\{}'.format(paths,list_1))\n",
    "        for list_2 in my_list_1:\n",
    "            df = pd.read_csv(r'{}\\{}\\{}'.format(paths,list_1,list_2), names = [\"Uid|Phone\"])\n",
    "            df_to_txt = df.to_csv(f'{d}\\\\{list_2}.txt',index=None)\n",
    "            # print(df_to_txt)\n",
    "            files = os.path.join(r'{}'.format(d), \"*.txt\")\n",
    "            files = glob.glob(files)\n",
    "            df = pd.concat(map(pd.read_csv, files))\n",
    "            filelist = glob.glob(os.path.join(d, \"*.txt\"))\n",
    "            for f in filelist:\n",
    "                os.remove(f)\n",
    "            df.to_csv( f'{d}\\\\{combine}', index=False)\n",
    "        path_combine = f'{d}\\\\{combine}'\n",
    "        print(path_combine)\n",
    "        split_files(path_combine)\n",
    "        convert_to_multiple_files(path_combine)\n",
    "        filelist = glob.glob(os.path.join(d, \"*_txt.txt\"))\n",
    "        for f in filelist:\n",
    "            os.remove(f)  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d725af2-5baa-4a6f-9743-68a094083c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62673bf5-7b50-452f-ab1c-1452a0772c37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "beedbe2faf2f7048d727558d0bc3221e7eba2a0b921cac4d4771b2feb8f74b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
